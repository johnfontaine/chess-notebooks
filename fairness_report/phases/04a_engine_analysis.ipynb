{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4a: Engine Analysis (Multi-Depth Stockfish)\n",
    "\n",
    "Run multi-depth Stockfish analysis on prioritized games.\n",
    "\n",
    "**Inputs:**\n",
    "- Phase 1: Raw games cache\n",
    "- Phase 3: high_priority_games.json\n",
    "\n",
    "**Outputs:**\n",
    "- `engine_analysis.parquet` - Position evaluations and accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (injected by Papermill)\n",
    "username = \"default_user\"  # Chess.com username\n",
    "analysis_depths = [5, 10, 20]  # Depths for multi-depth analysis\n",
    "engine_threads = 4  # CPU threads for Stockfish\n",
    "engine_hash_mb = 512  # Hash table size in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nsys.path.insert(0, '..')\nfrom common import (\n    setup_notebook, validate_parameters, print_section, print_subsection,\n    get_user_data_dir, save_phase_output, load_phase_output,\n    load_dataset_parquet, load_cached_games_v2,\n    CachedEngineAnalyzer, calculate_centipawn_loss, calculate_game_accuracy_simple,\n    parse_pgn_file,\n    ENGINE_CACHE_DIR,\n    # Fragility & Complexity\n    calculate_fragility_simple,\n    # Game phase detection\n    detect_game_phase, GamePhase,\n    # Engine complexity heuristics\n    PositionComplexityHeuristics,\n    categorize_complexity,\n)\nimport chess\nimport chess.pgn\nimport io\nimport json\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nsetup_notebook()\nvalidate_parameters(username)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load data\nprint_section(f\"ENGINE ANALYSIS: {username}\")\n\nuser_data_dir = get_user_data_dir(username)\nMIN_GAMES_FOR_ANALYSIS = 10  # Minimum games to analyze\n\n# Load high priority games from phase 3, or fall back to random selection\ntry:\n    priority_data = load_phase_output(username, \"phase3\", \"high_priority_games.json\")\n    game_ids_to_analyze = set(priority_data['game_ids'])\n    print(f\"High priority games from phase 3: {len(game_ids_to_analyze)}\")\nexcept FileNotFoundError:\n    print(\"Phase 3 output not found, falling back to game selection...\")\n    game_ids_to_analyze = set()\n\n# Load raw games cache\ncache_dir = user_data_dir / \"games_cache\"\nif cache_dir.exists():\n    all_games_raw, _ = load_cached_games_v2(cache_dir)\nelse:\n    # Try loading from user data directory\n    cache_dir = user_data_dir\n    all_games_raw, _ = load_cached_games_v2(cache_dir)\n\nprint(f\"Raw games loaded: {len(all_games_raw)}\")\n\n# Fallback: if no high priority games or not enough, select from all games\nif len(game_ids_to_analyze) < MIN_GAMES_FOR_ANALYSIS:\n    print(f\"\\nOnly {len(game_ids_to_analyze)} games from phase 3, need at least {MIN_GAMES_FOR_ANALYSIS}\")\n    print(\"Selecting additional games for analysis...\")\n    \n    # Extract game IDs from raw games\n    all_game_ids = []\n    for game in all_games_raw:\n        url = game.get('url', '')\n        if url:\n            game_id = url.split('/')[-1]\n            all_game_ids.append(game_id)\n    \n    # Add games until we have enough (prioritize wins for more interesting analysis)\n    wins_first = []\n    others = []\n    for game in all_games_raw:\n        url = game.get('url', '')\n        game_id = url.split('/')[-1] if url else None\n        if game_id and game_id not in game_ids_to_analyze:\n            # Check if player won\n            white = game.get('white', {})\n            black = game.get('black', {})\n            player_won = (\n                (white.get('username', '').lower() == username.lower() and white.get('result') == 'win') or\n                (black.get('username', '').lower() == username.lower() and black.get('result') == 'win')\n            )\n            if player_won:\n                wins_first.append(game_id)\n            else:\n                others.append(game_id)\n    \n    # Add wins first, then others\n    needed = MIN_GAMES_FOR_ANALYSIS - len(game_ids_to_analyze)\n    for game_id in wins_first[:needed]:\n        game_ids_to_analyze.add(game_id)\n        needed -= 1\n        if needed <= 0:\n            break\n    \n    if needed > 0:\n        for game_id in others[:needed]:\n            game_ids_to_analyze.add(game_id)\n    \n    print(f\"Final game count for analysis: {len(game_ids_to_analyze)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get PGN from raw game\n",
    "def get_game_pgn(game_id: str, all_games: list) -> chess.pgn.Game:\n",
    "    \"\"\"Extract PGN for a specific game.\"\"\"\n",
    "    for game in all_games:\n",
    "        url = game.get('url', '')\n",
    "        if game_id in url or url.endswith(f'/{game_id}'):\n",
    "            pgn_str = game.get('pgn', '')\n",
    "            if pgn_str:\n",
    "                return chess.pgn.read_game(io.StringIO(pgn_str))\n",
    "    return None\n",
    "\n",
    "# Filter games to analyze\n",
    "games_to_process = []\n",
    "for game_id in game_ids_to_analyze:\n",
    "    pgn = get_game_pgn(game_id, all_games_raw)\n",
    "    if pgn:\n",
    "        games_to_process.append((game_id, pgn))\n",
    "\n",
    "print(f\"Games with PGN found: {len(games_to_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run multi-depth engine analysis\nprint_subsection(\"RUNNING STOCKFISH ANALYSIS\")\nprint(f\"Depths: {analysis_depths}\")\nprint(f\"Engine threads: {engine_threads}\")\nprint(f\"Hash size: {engine_hash_mb} MB\")\n\nanalysis_results = []\n\n\ndef classify_move_by_cpl(cpl: float) -> str:\n    \"\"\"\n    Classify a move based on centipawn loss.\n    \n    Classification thresholds:\n    - Best: 0 CPL\n    - Excellent: 1-9 CPL\n    - Good: 10-24 CPL\n    - Inaccuracy: 25-49 CPL\n    - Mistake: 50-99 CPL\n    - Blunder: â‰¥100 CPL\n    \"\"\"\n    if cpl == 0:\n        return \"Best\"\n    elif cpl < 10:\n        return \"Excellent\"\n    elif cpl < 25:\n        return \"Good\"\n    elif cpl < 50:\n        return \"Inaccuracy\"\n    elif cpl < 100:\n        return \"Mistake\"\n    else:\n        return \"Blunder\"\n\n\nwith CachedEngineAnalyzer(\n    depth=max(analysis_depths),\n    threads=engine_threads,\n    hash_mb=engine_hash_mb,\n    cache_dir=ENGINE_CACHE_DIR,\n) as engine:\n    for game_id, pgn in tqdm(games_to_process, desc=\"Analyzing games\"):\n        try:\n            # Determine player color\n            white = pgn.headers.get('White', '').lower()\n            black = pgn.headers.get('Black', '').lower()\n            player_is_white = username.lower() == white\n            \n            # Analyze each position\n            board = pgn.board()\n            positions = []\n            fragilities = []  # Track for peak detection\n            \n            for ply, move in enumerate(pgn.mainline_moves()):\n                is_white_move = (ply % 2 == 0)\n                is_player_move = is_white_move == player_is_white\n                \n                if is_player_move:\n                    # Store FEN before the move for key position rendering\n                    fen_before = board.fen()\n                    \n                    # Detect game phase\n                    phase = detect_game_phase(board)\n                    \n                    # Calculate fragility (cheap - no engine needed)\n                    fragility = calculate_fragility_simple(board)\n                    fragilities.append((ply, fragility))\n                    \n                    # Use extended multi-depth analysis with engine heuristics\n                    result = engine.analyze_multi_depth_extended(\n                        board, \n                        analysis_depths,\n                        multipv=2,  # For gap metric\n                        capture_search_stats=True,\n                    )\n                    best_eval = result.evaluations.get(max(analysis_depths), 0)\n                    best_move = result.best_moves.get(max(analysis_depths), '')\n                    \n                    # Extract engine complexity heuristics\n                    heuristics = result.complexity_heuristics\n                    \n                    # Push move and get post-move eval (also from white's perspective)\n                    board.push(move)\n                    post_result = engine.analyze(board, max(analysis_depths))\n                    post_eval = post_result.get('score', 0)\n                    \n                    # Calculate centipawn loss using the proper function\n                    # Both evals are from white's perspective\n                    cpl = calculate_centipawn_loss(best_eval, post_eval, is_white_move)\n                    \n                    # Classify move by CPL (not accuracy!)\n                    move_class = classify_move_by_cpl(cpl)\n                    \n                    positions.append({\n                        'ply': ply,\n                        'fen': fen_before,  # Store FEN for key position rendering\n                        'move': move.uci(),\n                        'best_move': best_move,\n                        'eval_before': best_eval,\n                        'eval_after': post_eval,\n                        'cpl': cpl,\n                        'move_class': move_class,\n                        'is_best': move.uci() == best_move,\n                        'move_consistency': result.move_consistency,\n                        'eval_swing': result.eval_swing,\n                        # Game phase\n                        'phase': phase.value,\n                        # Graph-based fragility\n                        'fragility': fragility,\n                        # Engine complexity heuristics\n                        'eval_volatility': heuristics.eval_volatility if heuristics else 0,\n                        'eval_volatility_normalized': heuristics.eval_volatility_normalized if heuristics else 0,\n                        'gap_cp': heuristics.gap_at_max_depth if heuristics else 0,\n                        'avg_gap_cp': heuristics.avg_gap if heuristics else 0,\n                        'convergence_depth': heuristics.convergence_depth if heuristics else None,\n                        'branching_factor': heuristics.branching_factor_estimate if heuristics else 3.5,\n                        'engine_complexity_score': heuristics.complexity_score if heuristics else 0,\n                        'engine_complexity_category': heuristics.complexity_category if heuristics else 'UNKNOWN',\n                        'total_nodes': heuristics.total_nodes if heuristics else 0,\n                        # Legal moves count from the position\n                        'legal_moves': len(list(chess.Board(fen_before).legal_moves)),\n                    })\n                else:\n                    board.push(move)\n            \n            # Mark positions relative to fragility peak\n            if fragilities:\n                # Find peak fragility\n                peak_ply, peak_fragility = max(fragilities, key=lambda x: x[1])\n                \n                # Mark positions as pre-peak (5 moves before peak is decisive zone)\n                for pos in positions:\n                    pos_ply = pos['ply']\n                    pos['is_pre_fragility_peak'] = (pos_ply < peak_ply and pos_ply >= peak_ply - 10)\n                    pos['peak_fragility'] = peak_fragility\n            \n            # Calculate game-level metrics\n            if positions:\n                cpl_values = [p['cpl'] for p in positions]\n                acpl = np.mean(cpl_values)\n                accuracy = calculate_game_accuracy_simple(cpl_values)\n                best_move_rate = sum(1 for p in positions if p['is_best']) / len(positions)\n                \n                # Game-level fragility\n                avg_fragility = np.mean([p['fragility'] for p in positions])\n                \n                # Game-level engine complexity heuristics\n                avg_eval_volatility = np.mean([p['eval_volatility'] for p in positions])\n                avg_gap_cp = np.mean([p['gap_cp'] for p in positions])\n                avg_engine_complexity = np.mean([p['engine_complexity_score'] for p in positions])\n                high_complexity_moves = sum(1 for p in positions \n                                           if p['engine_complexity_category'] in ['HIGH', 'VERY_HIGH'])\n                \n                analysis_results.append({\n                    'game_id': game_id,\n                    'moves_analyzed': len(positions),\n                    'acpl': acpl,\n                    'accuracy': accuracy,\n                    'best_move_rate': best_move_rate,\n                    'blunders': sum(1 for p in positions if p['move_class'] == 'Blunder'),\n                    'mistakes': sum(1 for p in positions if p['move_class'] == 'Mistake'),\n                    'inaccuracies': sum(1 for p in positions if p['move_class'] == 'Inaccuracy'),\n                    'avg_fragility': avg_fragility,\n                    # Engine complexity heuristics (aggregated)\n                    'avg_eval_volatility': avg_eval_volatility,\n                    'avg_gap_cp': avg_gap_cp,\n                    'avg_engine_complexity': avg_engine_complexity,\n                    'high_complexity_moves': high_complexity_moves,\n                    'positions': positions,\n                })\n        except Exception as e:\n            print(f\"Error analyzing {game_id}: {e}\")\n            continue\n    \n    # Print cache stats\n    stats = engine.cache_stats()\n    print(f\"\\nCache stats: {stats['hit_rate']} hit rate ({stats['cache_hits']} hits, {stats['cache_misses']} misses)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display results\nprint_subsection(\"ENGINE ANALYSIS RESULTS\")\n\nif analysis_results:\n    results_df = pd.DataFrame([{\n        'game_id': r['game_id'],\n        'moves': r['moves_analyzed'],\n        'acpl': r['acpl'],\n        'accuracy': r['accuracy'],\n        'best_move_rate': r['best_move_rate'],\n        'blunders': r['blunders'],\n        'mistakes': r['mistakes'],\n        'inaccuracies': r['inaccuracies'],\n        'avg_fragility': r.get('avg_fragility', 0),\n        # Engine complexity heuristics\n        'avg_eval_volatility': r.get('avg_eval_volatility', 0),\n        'avg_gap_cp': r.get('avg_gap_cp', 0),\n        'avg_engine_complexity': r.get('avg_engine_complexity', 0),\n        'high_complexity_moves': r.get('high_complexity_moves', 0),\n    } for r in analysis_results])\n    \n    print(f\"Games analyzed: {len(results_df)}\")\n    print(f\"\\nSummary statistics:\")\n    print(f\"  Average ACPL: {results_df['acpl'].mean():.1f}\")\n    print(f\"  Average Accuracy: {results_df['accuracy'].mean():.1f}%\")\n    print(f\"  Average Best Move Rate: {results_df['best_move_rate'].mean():.1%}\")\n    print(f\"  Average Fragility: {results_df['avg_fragility'].mean():.3f}\")\n    \n    print(f\"\\nEngine Complexity Heuristics:\")\n    print(f\"  Average Eval Volatility: {results_df['avg_eval_volatility'].mean():.1f}cp\")\n    print(f\"  Average Gap to 2nd Best: {results_df['avg_gap_cp'].mean():.0f}cp\")\n    print(f\"  Average Engine Complexity: {results_df['avg_engine_complexity'].mean():.1%}\")\n    print(f\"  High Complexity Moves: {results_df['high_complexity_moves'].sum()} total\")\n    \n    print(f\"\\nTop 10 games by accuracy:\")\n    print(results_df.nlargest(10, 'accuracy')[['game_id', 'acpl', 'accuracy', 'best_move_rate', 'avg_engine_complexity']].to_string())\nelse:\n    print(\"No games were analyzed.\")\n    results_df = pd.DataFrame()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "if not results_df.empty:\n",
    "    save_phase_output(username, \"phase4a\", \"engine_analysis.parquet\", results_df)\n",
    "    \n",
    "    # Save detailed positions separately (large)\n",
    "    detailed_output = {\n",
    "        \"username\": username,\n",
    "        \"depths\": analysis_depths,\n",
    "        \"games\": analysis_results,\n",
    "    }\n",
    "    save_phase_output(username, \"phase4a\", \"engine_positions.json\", detailed_output)\n",
    "\n",
    "print(f\"\\nPhase 4a complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization\nimport matplotlib.pyplot as plt\n\nif not results_df.empty:\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    # ACPL distribution\n    axes[0].hist(results_df['acpl'], bins=20, color='steelblue', edgecolor='white')\n    axes[0].axvline(results_df['acpl'].mean(), color='red', linestyle='--', label=f\"Mean: {results_df['acpl'].mean():.1f}\")\n    axes[0].set_xlabel('ACPL')\n    axes[0].set_ylabel('Games')\n    axes[0].set_title('ACPL Distribution')\n    axes[0].legend()\n    \n    # Accuracy distribution (0-100 scale)\n    axes[1].hist(results_df['accuracy'], bins=20, color='green', edgecolor='white')\n    axes[1].axvline(results_df['accuracy'].mean(), color='red', linestyle='--', label=f\"Mean: {results_df['accuracy'].mean():.1f}%\")\n    axes[1].set_xlabel('Accuracy (%)')\n    axes[1].set_ylabel('Games')\n    axes[1].set_title('Accuracy Distribution')\n    axes[1].legend()\n    \n    # Best move rate distribution\n    axes[2].hist(results_df['best_move_rate'], bins=20, color='purple', edgecolor='white')\n    axes[2].axvline(results_df['best_move_rate'].mean(), color='red', linestyle='--', label=f\"Mean: {results_df['best_move_rate'].mean():.1%}\")\n    axes[2].set_xlabel('Best Move Rate')\n    axes[2].set_ylabel('Games')\n    axes[2].set_title('Best Move Rate Distribution')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}