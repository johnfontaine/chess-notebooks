{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4b: Ken Regan Analysis (IPR & Z-Score)\n",
    "\n",
    "Apply Ken Regan's cheat detection methodology using IPR and Z-scores.\n",
    "\n",
    "**Inputs:**\n",
    "- Phase 4a: engine_analysis.parquet, engine_positions.json\n",
    "\n",
    "**Outputs:**\n",
    "- `regan_analysis.parquet` - Per-game Regan metrics\n",
    "- `suspicious_positions.json` - Flagged positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (injected by Papermill)\n",
    "username = \"default_user\"  # Chess.com username\n",
    "z_score_threshold = 2.0  # Z-score threshold for flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nsys.path.insert(0, '..')\nfrom common import (\n    setup_notebook, validate_parameters, print_section, print_subsection,\n    get_user_data_dir, save_phase_output, load_phase_output,\n    load_dataset_parquet, load_baseline,\n    analyze_game_regan, ReganAnalysisResult,\n)\nimport json\nimport pandas as pd\nimport numpy as np\nfrom dataclasses import asdict\n\nsetup_notebook()\nvalidate_parameters(username)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load data\nprint_section(f\"REGAN ANALYSIS: {username}\")\n\n# Load engine analysis results (optional - phase 4a may not have run)\ntry:\n    engine_df = load_phase_output(username, \"phase4a\", \"engine_analysis.parquet\")\n    print(f\"Engine analysis loaded: {len(engine_df)} games\")\nexcept FileNotFoundError:\n    engine_df = pd.DataFrame()\n    print(\"No engine analysis found (phase 4a may not have completed)\")\n\n# Load detailed positions\ntry:\n    engine_positions = load_phase_output(username, \"phase4a\", \"engine_positions.json\")\n    print(f\"Position data loaded: {len(engine_positions.get('games', []))} games\")\nexcept FileNotFoundError:\n    engine_positions = {\"games\": []}\n    print(\"No position data found\")\n\n# Load baselines for comparison\ntrusted_baseline = load_baseline(\"trusted\")\ncheater_baseline = load_baseline(\"cheater\")\n\nif engine_df.empty and not engine_positions.get('games'):\n    print(\"\\nWARNING: No engine analysis data available. Regan analysis will be skipped.\")\n    print(\"Run phase 4a (engine analysis) first to enable Regan analysis.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ken Regan Analysis\nprint_subsection(\"CALCULATING IPR AND Z-SCORES\")\n\nregan_results = []\n\n# Load games dataframe to get player ratings\nuser_data_dir = get_user_data_dir(username)\ntry:\n    games_df = pd.DataFrame(load_dataset_parquet(user_data_dir / \"games.parquet\"))\n    game_ratings = dict(zip(games_df['game_id'].astype(str), games_df['player_rating']))\nexcept Exception:\n    game_ratings = {}\n\nfor game_data in engine_positions.get('games', []):\n    game_id = game_data['game_id']\n    positions = game_data.get('positions', [])\n    \n    if not positions:\n        continue\n    \n    # Get player's rating for this game (or default to 1500)\n    official_elo = game_ratings.get(str(game_id), 1500)\n    if pd.isna(official_elo):\n        official_elo = 1500\n    official_elo = int(official_elo)\n    \n    # Use analyze_game_regan for proper IPR and z-score calculation\n    # The function expects positions with: best_move, move, eval_before, eval_after\n    regan_result = analyze_game_regan(\n        positions=positions,\n        official_elo=official_elo,\n        exclude_book_moves=0,  # Already filtered in engine analysis\n    )\n    \n    regan_results.append({\n        'game_id': game_id,\n        'official_elo': regan_result.official_elo,\n        'ipr': regan_result.ipr,\n        'elo_difference': regan_result.elo_difference,\n        'z_score': regan_result.z_score,\n        'move_match_rate': regan_result.move_match_rate,\n        'avg_partial_credit': regan_result.avg_partial_credit,\n        'is_flagged': regan_result.is_suspicious,\n        'suspicion_level': regan_result.suspicion_level,\n        'total_moves': regan_result.num_positions,\n        'acpl': game_data.get('acpl', 0),\n    })\n\nprint(f\"Analyzed {len(regan_results)} games\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display Regan analysis results\nprint_subsection(\"REGAN ANALYSIS RESULTS\")\n\nif regan_results:\n    regan_df = pd.DataFrame(regan_results)\n    \n    print(f\"\\nSummary:\")\n    print(f\"  Games analyzed: {len(regan_df)}\")\n    print(f\"  Average official Elo: {regan_df['official_elo'].mean():.0f}\")\n    print(f\"  Average IPR: {regan_df['ipr'].mean():.0f}\")\n    print(f\"  Average Elo difference (IPR - Elo): {regan_df['elo_difference'].mean():.0f}\")\n    print(f\"  Average Z-score: {regan_df['z_score'].mean():.2f}\")\n    print(f\"  Average move match rate: {regan_df['move_match_rate'].mean():.1%}\")\n    print(f\"  Games flagged: {regan_df['is_flagged'].sum()}\")\n    \n    # Show flagged games\n    flagged = regan_df[regan_df['is_flagged']]\n    if not flagged.empty:\n        print(f\"\\nFlagged games:\")\n        print(flagged[['game_id', 'official_elo', 'ipr', 'z_score', 'suspicion_level']].to_string())\n    \n    # Show games by suspicion level\n    print(f\"\\nSuspicion level breakdown:\")\n    print(regan_df['suspicion_level'].value_counts().to_string())\n    \n    # Compare to baseline\n    if trusted_baseline:\n        print(f\"\\nBaseline comparison:\")\n        print(f\"  Player avg Z-score: {regan_df['z_score'].mean():.2f}\")\n        print(f\"  Player avg IPR - Elo: {regan_df['elo_difference'].mean():.0f}\")\nelse:\n    regan_df = pd.DataFrame()\n    print(\"No Regan analysis results.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Correlate with rating improvement\nprint_subsection(\"RATING CORRELATION\")\n\n# Load rating timeline if available\ntry:\n    quick_stats = load_phase_output(username, \"phase2\", \"quick_stats.json\")\n    improvement = quick_stats.get('glicko2', {}).get('improvement')\n    \n    if improvement:\n        trend = improvement.get('trend', 'N/A')\n        print(f\"Rating improvement trend: {trend}\")\n        # Use glicko2_slope or elo_slope instead of rating_per_period\n        glicko_slope = improvement.get('glicko2_slope', 0)\n        elo_slope = improvement.get('elo_slope', 0)\n        print(f\"Glicko-2 slope: {glicko_slope:.1f} per 100 games\")\n        print(f\"Elo slope: {elo_slope:.1f} per 100 games\")\n        \n        # High Z-scores during rapid improvement could be suspicious\n        if trend == 'improving' and not regan_df.empty:\n            avg_z = regan_df['z_score'].mean()\n            if avg_z > 1.5:\n                print(f\"\\nWARNING: High Z-scores ({avg_z:.2f}) during improvement period\")\n    else:\n        print(\"Insufficient data for improvement analysis\")\nexcept FileNotFoundError:\n    print(\"No rating data available for correlation.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "if not regan_df.empty:\n",
    "    save_phase_output(username, \"phase4b\", \"regan_analysis.parquet\", regan_df)\n",
    "    \n",
    "    # Save flagged positions detail\n",
    "    flagged_detail = {\n",
    "        \"username\": username,\n",
    "        \"z_score_threshold\": z_score_threshold,\n",
    "        \"flagged_games\": regan_df[regan_df['is_flagged']].to_dict('records'),\n",
    "        \"summary\": {\n",
    "            \"total_games\": len(regan_df),\n",
    "            \"flagged_count\": int(regan_df['is_flagged'].sum()),\n",
    "            \"avg_z_score\": float(regan_df['z_score'].mean()),\n",
    "            \"max_z_score\": float(regan_df['z_score'].max()),\n",
    "        }\n",
    "    }\n",
    "    save_phase_output(username, \"phase4b\", \"suspicious_positions.json\", flagged_detail)\n",
    "\n",
    "print(f\"\\nPhase 4b complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization\nimport matplotlib.pyplot as plt\n\nif not regan_df.empty:\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    # Z-score distribution\n    axes[0].hist(regan_df['z_score'], bins=20, color='steelblue', edgecolor='white')\n    axes[0].axvline(2.0, color='red', linestyle='--', label='Threshold (2.0)')\n    axes[0].axvline(regan_df['z_score'].mean(), color='green', linestyle='--', label=f\"Mean ({regan_df['z_score'].mean():.2f})\")\n    axes[0].set_xlabel('Z-Score')\n    axes[0].set_ylabel('Games')\n    axes[0].set_title('Z-Score Distribution')\n    axes[0].legend()\n    \n    # IPR vs Official Elo\n    axes[1].scatter(regan_df['official_elo'], regan_df['ipr'], \n                   c=['red' if f else 'blue' for f in regan_df['is_flagged']], alpha=0.6)\n    min_elo = min(regan_df['official_elo'].min(), regan_df['ipr'].min()) - 50\n    max_elo = max(regan_df['official_elo'].max(), regan_df['ipr'].max()) + 50\n    axes[1].plot([min_elo, max_elo], [min_elo, max_elo], 'k--', alpha=0.3, label='IPR = Elo')\n    axes[1].set_xlabel('Official Elo')\n    axes[1].set_ylabel('IPR (Intrinsic Performance Rating)')\n    axes[1].set_title('IPR vs Official Elo')\n    axes[1].legend()\n    \n    # Move match rate distribution\n    axes[2].hist(regan_df['move_match_rate'], bins=20, color='purple', edgecolor='white')\n    axes[2].axvline(regan_df['move_match_rate'].mean(), color='red', linestyle='--', \n                   label=f\"Mean ({regan_df['move_match_rate'].mean():.1%})\")\n    axes[2].set_xlabel('Move Match Rate')\n    axes[2].set_ylabel('Games')\n    axes[2].set_title('Best Move Match Rate')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}