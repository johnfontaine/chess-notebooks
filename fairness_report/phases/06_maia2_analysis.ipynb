{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 6: Maia2 Humanness Analysis\n\nAnalyze moves for human-like patterns using Maia2 neural network predictions.\n\n**Inputs:**\n- Phase 1: games.parquet, raw games\n- Phase 3: high_priority_games.json\n\n**Outputs:**\n- `maia2_analysis.parquet` - Humanness scores per game\n- `maia2_positions.parquet` - Position-level Maia2 data (probability, rank) for ALL positions\n- `surprising_moves.json` - Moves that deviate from human predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": "# Parameters (injected by Papermill)\nusername = \"default_user\"  # Chess.com username\nmaia_model_path = \"\"  # Path to Maia2 model (empty string = auto-detect)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nsys.path.insert(0, '..')\nfrom common import (\n    setup_notebook, validate_parameters, print_section, print_subsection,\n    get_user_data_dir, save_phase_output, load_phase_output,\n    load_dataset_parquet, load_cached_games_v2,\n    analyze_game_maia2, calculate_humanness_score, get_surprising_moves,\n    compare_to_stockfish,\n    PROJECT_ROOT,\n    detect_game_phase, GamePhase,  # For filtering opening phase moves\n)\nimport chess\nimport chess.pgn\nimport io\nimport json\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nsetup_notebook()\nvalidate_parameters(username)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check for Maia2 library availability\nprint_section(f\"MAIA2 HUMANNESS ANALYSIS: {username}\")\n\n# Check if maia2 library is installed\ntry:\n    import maia2\n    maia_available = True\n    print(\"Maia2 library found\")\nexcept ImportError:\n    maia_available = False\n    print(\"WARNING: maia2 library not installed. Humanness analysis will be limited.\")\n    print(\"Install with: pip install maia2\")\n    print(\"Models will be downloaded automatically on first use.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load data\nuser_data_dir = get_user_data_dir(username)\nMIN_GAMES_FOR_ANALYSIS = 10  # Minimum games to analyze\n\n# Load high priority games from phase 3, or fall back to selection\ntry:\n    priority_data = load_phase_output(username, \"phase3\", \"high_priority_games.json\")\n    game_ids_to_analyze = set(priority_data['game_ids'])\n    print(f\"High priority games from phase 3: {len(game_ids_to_analyze)}\")\nexcept FileNotFoundError:\n    print(\"Phase 3 output not found, will select games for analysis...\")\n    game_ids_to_analyze = set()\n\n# Load raw games\nall_games_raw, _ = load_cached_games_v2(user_data_dir)\nprint(f\"Raw games loaded: {len(all_games_raw)}\")\n\n# Ensure we have enough games for meaningful analysis\nif len(game_ids_to_analyze) < MIN_GAMES_FOR_ANALYSIS:\n    print(f\"\\nOnly {len(game_ids_to_analyze)} games from phase 3, need at least {MIN_GAMES_FOR_ANALYSIS}\")\n    print(\"Selecting additional games for analysis...\")\n    \n    # Load games dataframe to get game IDs\n    games_df = pd.DataFrame(load_dataset_parquet(user_data_dir / \"games.parquet\"))\n    all_game_ids = set(games_df['game_id'].tolist())\n    \n    # Add games until we have enough (prioritize wins)\n    wins = games_df[games_df['player_result'] == 'win']['game_id'].tolist()\n    others = games_df[games_df['player_result'] != 'win']['game_id'].tolist()\n    \n    needed = min(MIN_GAMES_FOR_ANALYSIS, len(all_game_ids)) - len(game_ids_to_analyze)\n    \n    for game_id in wins:\n        if game_id not in game_ids_to_analyze:\n            game_ids_to_analyze.add(game_id)\n            needed -= 1\n            if needed <= 0:\n                break\n    \n    if needed > 0:\n        for game_id in others:\n            if game_id not in game_ids_to_analyze:\n                game_ids_to_analyze.add(game_id)\n                needed -= 1\n                if needed <= 0:\n                    break\n    \n    print(f\"Final game count for analysis: {len(game_ids_to_analyze)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Helper to extract positions and metadata from PGN\ndef extract_game_data(game_id: str, all_games: list, target_username: str):\n    \"\"\"Extract positions, player color, and ratings from a game.\"\"\"\n    for game in all_games:\n        url = game.get('url', '')\n        if game_id in url or url.endswith(f'/{game_id}'):\n            pgn_str = game.get('pgn', '')\n            if not pgn_str:\n                return None\n            \n            pgn = chess.pgn.read_game(io.StringIO(pgn_str))\n            if not pgn:\n                return None\n            \n            # Determine player color and get ratings\n            white_player = pgn.headers.get('White', '').lower()\n            black_player = pgn.headers.get('Black', '').lower()\n            player_is_white = target_username.lower() == white_player\n            \n            # Get Elo ratings from headers\n            try:\n                white_elo = int(pgn.headers.get('WhiteElo', 1500))\n                black_elo = int(pgn.headers.get('BlackElo', 1500))\n            except ValueError:\n                white_elo = black_elo = 1500\n            \n            if player_is_white:\n                player_elo = white_elo\n                opponent_elo = black_elo\n            else:\n                player_elo = black_elo\n                opponent_elo = white_elo\n            \n            # Determine game type from time control\n            time_control = pgn.headers.get('TimeControl', '')\n            if 'rapid' in game.get('time_class', '').lower() or (time_control and int(time_control.split('+')[0]) >= 600):\n                game_type = 'rapid'\n            else:\n                game_type = 'blitz'\n            \n            # Extract positions with player moves\n            positions = []\n            board = pgn.board()\n            for ply, move in enumerate(pgn.mainline_moves()):\n                is_player_move = (ply % 2 == 0) == player_is_white\n                if is_player_move:\n                    positions.append({\n                        'fen': board.fen(),\n                        'move': move.uci(),\n                        'ply': ply,\n                    })\n                board.push(move)\n            \n            return {\n                'pgn': pgn,\n                'positions': positions,\n                'player_is_white': player_is_white,\n                'player_elo': player_elo,\n                'opponent_elo': opponent_elo,\n                'game_type': game_type,\n            }\n    return None\n\n# Extract data for games to analyze\ngames_to_process = []\nfor game_id in game_ids_to_analyze:\n    game_data = extract_game_data(game_id, all_games_raw, username)\n    if game_data and game_data['positions']:\n        games_to_process.append((game_id, game_data))\n\nprint(f\"Games with valid positions: {len(games_to_process)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run Maia2 analysis (if available) or simplified humanness analysis\nprint_subsection(\"ANALYZING HUMANNESS\")\n\n# Threshold for flagging surprising moves - only flag moves with <1% probability\n# Moves above this threshold are generally within normal human variation\nSURPRISING_MOVE_THRESHOLD = 0.01  # 1%\n# Disable rank-based filtering by setting a very high threshold\nSURPRISING_RANK_THRESHOLD = 100  # Effectively disabled\n\ndef is_opening_position(fen: str) -> bool:\n    \"\"\"Check if a position is still in the opening phase.\"\"\"\n    try:\n        board = chess.Board(fen)\n        phase = detect_game_phase(board)\n        return phase == GamePhase.OPENING\n    except Exception:\n        return False\n\nmaia_results = []\nall_surprising_moves = []\nall_position_data = []  # Store ALL position-level Maia2 data for cross-reference\n\nfor game_id, game_data in tqdm(games_to_process, desc=\"Analyzing games\"):\n    try:\n        if maia_available:\n            # Full Maia2 analysis using correct API\n            maia2_result = analyze_game_maia2(\n                positions=game_data['positions'],\n                player_elo=game_data['player_elo'],\n                opponent_elo=game_data['opponent_elo'],\n                game_type=game_data['game_type'],\n            )\n            \n            if maia2_result:\n                # calculate_humanness_score expects list of Maia2Result objects\n                humanness = calculate_humanness_score(maia2_result)\n                surprising = get_surprising_moves(\n                    maia2_result, \n                    probability_threshold=SURPRISING_MOVE_THRESHOLD,\n                    rank_threshold=SURPRISING_RANK_THRESHOLD,\n                )\n                \n                maia_results.append({\n                    'game_id': game_id,\n                    'humanness_score': humanness.get('humanness_score', 0),\n                    'moves_analyzed': humanness.get('num_positions', 0),\n                    'avg_maia_probability': humanness.get('avg_move_probability', 0),\n                    'top_choice_rate': humanness.get('top_choice_rate', 0),\n                    'avg_move_rank': humanness.get('avg_move_rank', 0),\n                    'surprising_moves': len(surprising),\n                })\n                \n                # Save ALL position-level Maia2 data for cross-reference with engine analysis\n                for r in maia2_result:\n                    all_position_data.append({\n                        'game_id': game_id,\n                        'fen': r.fen,\n                        'move': r.played_move,\n                        'probability': r.move_probability,\n                        'rank': r.move_rank,\n                        'top_move': r.top_move,\n                        'top_move_probability': r.top_move_probability,\n                    })\n                \n                if surprising:\n                    # Filter out opening phase moves - opening moves are expected to be \"book\"\n                    # moves and shouldn't be flagged as surprising\n                    filtered_moves = []\n                    for s in surprising:\n                        if not is_opening_position(s.fen):\n                            filtered_moves.append({\n                                'fen': s.fen, \n                                'move': s.played_move, \n                                'probability': s.move_probability, \n                                'rank': s.move_rank,\n                                'top_move': s.top_move,\n                                'top_move_probability': s.top_move_probability,\n                            })\n                    \n                    if filtered_moves:\n                        all_surprising_moves.append({\n                            'game_id': game_id,\n                            'moves': filtered_moves,\n                            'player_is_white': game_data['player_is_white'],  # For board orientation\n                        })\n        else:\n            # Simplified analysis without Maia2 library\n            # Use move complexity/commonality as proxy for humanness\n            positions = game_data['positions']\n            pgn = game_data['pgn']\n            player_is_white = game_data['player_is_white']\n            \n            board = pgn.board()\n            player_moves = []\n            \n            for ply, move in enumerate(pgn.mainline_moves()):\n                is_player_move = (ply % 2 == 0) == player_is_white\n                if is_player_move:\n                    # Simple heuristics for \"humanness\"\n                    legal_moves = list(board.legal_moves)\n                    player_moves.append({\n                        'ply': ply,\n                        'move': move.uci(),\n                        'legal_moves': len(legal_moves),\n                        'is_capture': board.is_capture(move),\n                        'is_check': board.gives_check(move),\n                    })\n                board.push(move)\n            \n            if player_moves:\n                # Calculate simplified humanness score\n                # (captures and checks are more \"obviously human\")\n                obvious_moves = sum(1 for m in player_moves if m['is_capture'] or m['is_check'])\n                humanness = obvious_moves / len(player_moves) if player_moves else 0\n                \n                maia_results.append({\n                    'game_id': game_id,\n                    'humanness_score': humanness,\n                    'moves_analyzed': len(player_moves),\n                    'avg_maia_probability': 0,  # Not available without maia2\n                    'top_choice_rate': 0,\n                    'avg_move_rank': 0,\n                    'surprising_moves': 0,\n                    'note': 'simplified_analysis'\n                })\n    except Exception as e:\n        print(f\"Error analyzing {game_id}: {e}\")\n        continue\n\nprint(f\"\\nAnalyzed {len(maia_results)} games\")\nprint(f\"Games with surprising (non-opening) moves: {len(all_surprising_moves)}\")\nprint(f\"Total positions with Maia2 data: {len(all_position_data)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print_subsection(\"HUMANNESS RESULTS\")\n",
    "\n",
    "if maia_results:\n",
    "    maia_df = pd.DataFrame(maia_results)\n",
    "    \n",
    "    print(f\"Games analyzed: {len(maia_df)}\")\n",
    "    print(f\"\\nHumanness statistics:\")\n",
    "    print(f\"  Average humanness score: {maia_df['humanness_score'].mean():.2f}\")\n",
    "    \n",
    "    if maia_available:\n",
    "        print(f\"  Average Maia probability: {maia_df['avg_maia_probability'].mean():.2%}\")\n",
    "        print(f\"  Total surprising moves: {maia_df['surprising_moves'].sum()}\")\n",
    "    \n",
    "    # Games with lowest humanness (most engine-like)\n",
    "    print(f\"\\nGames with lowest humanness:\")\n",
    "    print(maia_df.nsmallest(5, 'humanness_score')[['game_id', 'humanness_score', 'moves_analyzed']].to_string())\n",
    "else:\n",
    "    maia_df = pd.DataFrame()\n",
    "    print(\"No Maia2 results available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save outputs\nif not maia_df.empty:\n    save_phase_output(username, \"phase6\", \"maia2_analysis.parquet\", maia_df)\n\n# Save ALL position-level Maia2 data for cross-reference with other phases\nif all_position_data:\n    position_df = pd.DataFrame(all_position_data)\n    save_phase_output(username, \"phase6\", \"maia2_positions.parquet\", position_df)\n    print(f\"Position-level Maia2 data saved: {len(position_df)} positions\")\n\n# Save surprising moves\nsurprising_output = {\n    \"username\": username,\n    \"maia_available\": maia_available,\n    \"games_analyzed\": len(maia_df) if not maia_df.empty else 0,\n    \"avg_humanness\": float(maia_df['humanness_score'].mean()) if not maia_df.empty else 0,\n    \"surprising_moves\": all_surprising_moves,\n}\nsave_phase_output(username, \"phase6\", \"surprising_moves.json\", surprising_output)\n\nprint(f\"\\nPhase 6 complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not maia_df.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Humanness score distribution\n",
    "    axes[0].hist(maia_df['humanness_score'], bins=20, color='steelblue', edgecolor='white')\n",
    "    axes[0].axvline(maia_df['humanness_score'].mean(), color='red', linestyle='--', \n",
    "                   label=f\"Mean: {maia_df['humanness_score'].mean():.2f}\")\n",
    "    axes[0].set_xlabel('Humanness Score')\n",
    "    axes[0].set_ylabel('Games')\n",
    "    axes[0].set_title('Humanness Score Distribution')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Humanness vs moves analyzed\n",
    "    axes[1].scatter(maia_df['moves_analyzed'], maia_df['humanness_score'], alpha=0.6)\n",
    "    axes[1].set_xlabel('Moves Analyzed')\n",
    "    axes[1].set_ylabel('Humanness Score')\n",
    "    axes[1].set_title('Humanness vs Game Length')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}