{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Quick Analysis\n",
    "\n",
    "Fast statistical analysis of game patterns without expensive engine evaluation.\n",
    "\n",
    "**Inputs:**\n",
    "- Phase 1 outputs (games.parquet, sessions.json)\n",
    "\n",
    "**Outputs:**\n",
    "- `elo_analysis.json` - Rating pattern analysis\n",
    "- `result_patterns.json` - Win/loss/draw patterns\n",
    "- `session_analysis.json` - Session pattern analysis\n",
    "- `quick_stats.json` - Combined quick statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (injected by Papermill)\n",
    "username = \"default_user\"  # Chess.com username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nsys.path.insert(0, '..')\nfrom common import (\n    setup_notebook, validate_parameters, print_section, print_subsection,\n    get_user_data_dir, get_phase_dir, save_phase_output, load_phase_output,\n    load_baseline, load_dataset_parquet,\n    analyze_elo_patterns, analyze_result_patterns, analyze_session_patterns,\n    track_rating_over_time, analyze_rating_improvement,\n    Glicko2Rating,\n    PROJECT_ROOT\n)\nimport json\nimport pandas as pd\nimport numpy as np\nfrom dataclasses import asdict\n\nsetup_notebook()\nvalidate_parameters(username)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load data from Phase 1\nprint_section(f\"QUICK ANALYSIS: {username}\")\n\nuser_data_dir = get_user_data_dir(username)\n\n# Load datasets\ngames_df = pd.DataFrame(load_dataset_parquet(user_data_dir / \"games.parquet\"))\nprint(f\"Games loaded: {len(games_df)}\")\n\n# Merge with aggregates if available\ntry:\n    aggregates_df = pd.DataFrame(load_dataset_parquet(user_data_dir / \"game_aggregates.parquet\"))\n    games_df = games_df.merge(aggregates_df, on='game_id', how='left', suffixes=('', '_agg'))\n    print(f\"Merged with aggregates\")\nexcept FileNotFoundError:\n    print(\"No aggregates file found\")\n\n# Load sessions\nwith open(user_data_dir / \"sessions.json\") as f:\n    sessions_data = json.load(f)\n\n# Load baselines\ntrusted_baseline = load_baseline(\"trusted\")\ncheater_baseline = load_baseline(\"cheater\")\nprint(f\"Baselines loaded: trusted={bool(trusted_baseline)}, cheater={bool(cheater_baseline)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Analysis\n",
    "print_subsection(\"SESSION ANALYSIS\")\n",
    "\n",
    "session_patterns = sessions_data.get('patterns', {})\n",
    "sessions = sessions_data.get('sessions', [])\n",
    "\n",
    "print(f\"Total sessions: {len(sessions)}\")\n",
    "if session_patterns:\n",
    "    print(f\"Average session length: {session_patterns.get('avg_session_length', 0):.1f} games\")\n",
    "    print(f\"Max session length: {session_patterns.get('max_session_length', 0)} games\")\n",
    "    print(f\"Average session duration: {session_patterns.get('avg_session_duration_minutes', 0):.0f} minutes\")\n",
    "\n",
    "session_analysis = {\n",
    "    \"total_sessions\": len(sessions),\n",
    "    \"patterns\": session_patterns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Rating Analysis (Chess.com Elo) - Separate by Time Class\nprint_subsection(\"RATING ANALYSIS\")\n\n# Get time classes in data\ntime_classes_in_data = games_df['time_class'].unique().tolist()\nprint(f\"Time classes: {time_classes_in_data}\")\n\n# Analyze overall\nelo_analysis = analyze_elo_patterns(games_df.to_dict('records'))\n\nprint(f\"\\nOverall Rating Stats:\")\nprint(f\"  Rating range: {elo_analysis.elo_min} - {elo_analysis.elo_max}\")\nprint(f\"  Rating change: {elo_analysis.elo_change:+d}\")\nprint(f\"  Win rate: {elo_analysis.win_rate:.1%}\")\nprint(f\"  Manipulation score: {elo_analysis.rating_manipulation_score:.3f}\")\n\n# Analyze by time class\nelo_by_time_class = {}\nfor tc in time_classes_in_data:\n    tc_games = games_df[games_df['time_class'] == tc].to_dict('records')\n    if tc_games:\n        tc_analysis = analyze_elo_patterns(tc_games)\n        elo_by_time_class[tc] = asdict(tc_analysis)\n        print(f\"\\n{tc.capitalize()} Rating Stats:\")\n        print(f\"  Games: {tc_analysis.total_games}\")\n        print(f\"  Rating: {tc_analysis.elo_min} - {tc_analysis.elo_max} (current: {tc_analysis.elo_end})\")\n        print(f\"  Win rate: {tc_analysis.win_rate:.1%}\")\n\n# Compare to baselines\nif trusted_baseline:\n    trusted_manip = trusted_baseline.get('elo_baseline', {}).get('manipulation_score_mean', 0)\n    trusted_max = trusted_baseline.get('elo_baseline', {}).get('manipulation_score_max', 0)\n    print(f\"\\nBaseline comparison:\")\n    print(f\"  Trusted avg: {trusted_manip:.3f}, max: {trusted_max:.3f}\")\n    if elo_analysis.rating_manipulation_score > trusted_max:\n        print(f\"  WARNING: Manipulation score exceeds trusted baseline max!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Glicko-2 Rating Analysis\nprint_subsection(\"GLICKO-2 ANALYSIS\")\n\n# Load raw games cache for Glicko-2 (needs nested white/black dicts)\nraw_games_cache_path = user_data_dir / \"games_cache.json\"\nif raw_games_cache_path.exists():\n    with open(raw_games_cache_path) as f:\n        raw_cache = json.load(f)\n    raw_games = raw_cache.get('games', [])\n    \n    # Track rating over time using raw game data\n    rating_timeline = track_rating_over_time(raw_games, username)\n    improvement_analysis = analyze_rating_improvement(rating_timeline)\n\n    print(f\"Rating periods: {len(rating_timeline)}\")\n    if not rating_timeline.empty:\n        print(f\"Final Glicko-2: {rating_timeline.iloc[-1]['rating']:.0f} (RD: {rating_timeline.iloc[-1]['rd']:.0f})\")\n        if improvement_analysis:\n            print(f\"Improvement trend: {improvement_analysis.trend}\")\n            print(f\"Glicko-2 slope: {improvement_analysis.glicko2_slope:.1f} per 100 games\")\n            print(f\"Elo slope: {improvement_analysis.elo_slope:.1f} per 100 games\")\n        else:\n            print(\"Insufficient data for improvement analysis\")\nelse:\n    print(\"Raw games cache not found, skipping Glicko-2 analysis\")\n    rating_timeline = pd.DataFrame()\n    improvement_analysis = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Result Patterns\nprint_subsection(\"RESULT PATTERNS\")\n\nresult_analysis = analyze_result_patterns(games_df.to_dict('records'))\n\n# Calculate totals from breakdown\ntotal_wins = result_analysis.wins_by_checkmate + result_analysis.wins_by_resignation + result_analysis.wins_by_timeout\ntotal_losses = result_analysis.losses_by_checkmate + result_analysis.losses_by_resignation + result_analysis.losses_by_timeout\ntotal_draws = result_analysis.draws_total\n\nprint(f\"Win/Draw/Loss: {total_wins}/{total_draws}/{total_losses}\")\nprint(f\"Checkmate rate: {result_analysis.checkmate_rate:.1%}\")\nprint(f\"Resignation rate: {result_analysis.resignation_rate:.1%}\")\nprint(f\"Timeout rate: {result_analysis.timeout_rate:.1%}\")\n\n# Compare to baselines\nif trusted_baseline:\n    trusted_timeout = trusted_baseline.get('timeout_baseline', {}).get('timeout_win_rate_mean', 0)\n    print(f\"\\nTimeout comparison:\")\n    print(f\"  Player timeout rate: {result_analysis.timeout_rate:.1%}\")\n    print(f\"  Trusted baseline: {trusted_timeout:.1%}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Opening Book Summary\nprint_subsection(\"OPENING BOOK\")\n\nwith open(user_data_dir / \"opening_book.json\") as f:\n    opening_book = json.load(f)\n\n# Handle both old format (ECO dict) and new format (positions dict)\nif 'positions' in opening_book:\n    # New format with position counts\n    positions = opening_book.get('positions', {})\n    common_positions = opening_book.get('common_positions', {})\n    print(f\"Unique positions: {opening_book.get('num_unique_positions', len(positions))}\")\n    print(f\"Common positions (3+ games): {opening_book.get('num_common_positions', len(common_positions))}\")\n    print(f\"Average opening depth: {opening_book.get('opening_depth_avg', 0):.1f} plies\")\n    \n    if common_positions:\n        print(f\"\\nMost common positions:\")\n        # Sort by count descending\n        sorted_positions = sorted(common_positions.items(), key=lambda x: x[1], reverse=True)[:5]\n        for fen, count in sorted_positions:\n            # Truncate FEN for display\n            short_fen = fen[:40] + \"...\" if len(fen) > 40 else fen\n            print(f\"  {short_fen}: {count} games\")\nelse:\n    # Old format with ECO codes\n    print(f\"Unique openings (ECO): {len(opening_book)}\")\n    \n    # Top openings\n    sorted_openings = sorted(opening_book.items(), key=lambda x: x[1].get('count', 0), reverse=True)[:10]\n    print(f\"\\nTop 10 openings:\")\n    for eco, stats in sorted_openings:\n        count = stats.get('count', 0)\n        wins = stats.get('wins', 0)\n        win_rate = wins / count if count > 0 else 0\n        print(f\"  {eco}: {count} games, {win_rate:.0%} win rate\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save quick stats\nopening_count = opening_book.get('num_unique_positions', len(opening_book)) if isinstance(opening_book, dict) else len(opening_book)\n\nquick_stats = {\n    \"username\": username,\n    \"total_games\": len(games_df),\n    \"time_classes\": time_classes_in_data,\n    \"elo_analysis\": asdict(elo_analysis),\n    \"elo_by_time_class\": elo_by_time_class,\n    \"result_patterns\": asdict(result_analysis),\n    \"session_analysis\": session_analysis,\n    \"glicko2\": {\n        \"periods\": len(rating_timeline),\n        \"improvement\": asdict(improvement_analysis) if improvement_analysis else None,\n    },\n    \"opening_count\": opening_count,\n}\n\nsave_phase_output(username, \"phase2\", \"quick_stats.json\", quick_stats)\nsave_phase_output(username, \"phase2\", \"elo_analysis.json\", asdict(elo_analysis))\nsave_phase_output(username, \"phase2\", \"elo_by_time_class.json\", elo_by_time_class)\nsave_phase_output(username, \"phase2\", \"result_patterns.json\", asdict(result_analysis))\nsave_phase_output(username, \"phase2\", \"session_analysis.json\", session_analysis)\n\nprint(f\"\\nPhase 2 complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization: Rating over time\nimport matplotlib.pyplot as plt\n\nif not rating_timeline.empty and len(rating_timeline) > 1:\n    fig, ax = plt.subplots(figsize=(12, 5))\n    \n    # Use rating column (Glicko-2)\n    ax.plot(range(len(rating_timeline)), rating_timeline['rating'], 'b-', linewidth=2, label='Glicko-2')\n    ax.fill_between(\n        range(len(rating_timeline)),\n        rating_timeline['rating'] - rating_timeline['rd'],\n        rating_timeline['rating'] + rating_timeline['rd'],\n        alpha=0.2\n    )\n    \n    # Also plot Chess.com Elo if available\n    if 'elo_end' in rating_timeline.columns:\n        ax.plot(range(len(rating_timeline)), rating_timeline['elo_end'], 'g--', linewidth=1, label='Chess.com Elo')\n    \n    ax.set_xlabel('Rating Period')\n    ax.set_ylabel('Rating')\n    ax.set_title(f'Rating Progression: {username}')\n    ax.legend()\n    plt.tight_layout()\n    plt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}